"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[3085],{3905:function(a,e,n){n.r(e),n.d(e,{MDXContext:function(){return l},MDXProvider:function(){return c},mdx:function(){return x},useMDXComponents:function(){return d},withMDXComponents:function(){return o}});var t=n(67294);function s(a,e,n){return e in a?Object.defineProperty(a,e,{value:n,enumerable:!0,configurable:!0,writable:!0}):a[e]=n,a}function m(){return m=Object.assign||function(a){for(var e=1;e<arguments.length;e++){var n=arguments[e];for(var t in n)Object.prototype.hasOwnProperty.call(n,t)&&(a[t]=n[t])}return a},m.apply(this,arguments)}function r(a,e){var n=Object.keys(a);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(a);e&&(t=t.filter((function(e){return Object.getOwnPropertyDescriptor(a,e).enumerable}))),n.push.apply(n,t)}return n}function p(a){for(var e=1;e<arguments.length;e++){var n=null!=arguments[e]?arguments[e]:{};e%2?r(Object(n),!0).forEach((function(e){s(a,e,n[e])})):Object.getOwnPropertyDescriptors?Object.defineProperties(a,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(e){Object.defineProperty(a,e,Object.getOwnPropertyDescriptor(n,e))}))}return a}function i(a,e){if(null==a)return{};var n,t,s=function(a,e){if(null==a)return{};var n,t,s={},m=Object.keys(a);for(t=0;t<m.length;t++)n=m[t],e.indexOf(n)>=0||(s[n]=a[n]);return s}(a,e);if(Object.getOwnPropertySymbols){var m=Object.getOwnPropertySymbols(a);for(t=0;t<m.length;t++)n=m[t],e.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(a,n)&&(s[n]=a[n])}return s}var l=t.createContext({}),o=function(a){return function(e){var n=d(e.components);return t.createElement(a,m({},e,{components:n}))}},d=function(a){var e=t.useContext(l),n=e;return a&&(n="function"==typeof a?a(e):p(p({},e),a)),n},c=function(a){var e=d(a.components);return t.createElement(l.Provider,{value:e},a.children)},N={inlineCode:"code",wrapper:function(a){var e=a.children;return t.createElement(t.Fragment,{},e)}},h=t.forwardRef((function(a,e){var n=a.components,s=a.mdxType,m=a.originalType,r=a.parentName,l=i(a,["components","mdxType","originalType","parentName"]),o=d(n),c=s,h=o["".concat(r,".").concat(c)]||o[c]||N[c]||m;return n?t.createElement(h,p(p({ref:e},l),{},{components:n})):t.createElement(h,p({ref:e},l))}));function x(a,e){var n=arguments,s=e&&e.mdxType;if("string"==typeof a||s){var m=n.length,r=new Array(m);r[0]=h;var p={};for(var i in e)hasOwnProperty.call(e,i)&&(p[i]=e[i]);p.originalType=a,p.mdxType="string"==typeof a?a:s,r[1]=p;for(var l=2;l<m;l++)r[l]=n[l];return t.createElement.apply(null,r)}return t.createElement.apply(null,n)}h.displayName="MDXCreateElement"},91262:function(a,e,n){n(67294),n(72389)},35818:function(a,e,n){n.r(e),n.d(e,{frontMatter:function(){return i},contentTitle:function(){return l},metadata:function(){return o},toc:function(){return d},default:function(){return N}});var t=n(87462),s=n(63366),m=(n(67294),n(3905)),r=n(44996),p=(n(91262),["components"]),i={title:"Analysis",sidebar_label:"Analysis",slug:"/overview/analysis"},l=void 0,o={unversionedId:"overview/analysis/analysis",id:"overview/analysis/analysis",title:"Analysis",description:"Inference results are useful not only for learning posterior distributions, but for verifying that inference ran correctly. We'll cover common techniques for analyzing results in this section. As is the case for everything else in this Overview, the code for this section is available as a notebook on GitHub and Colab.",source:"@site/../docs/overview/analysis/analysis.mdx",sourceDirName:"overview/analysis",slug:"/overview/analysis",permalink:"/docs/overview/analysis",editUrl:"https://github.com/facebookresearch/beanmachine/edit/main/website/../docs/overview/analysis/analysis.mdx",tags:[],version:"current",frontMatter:{title:"Analysis",sidebar_label:"Analysis",slug:"/overview/analysis"},sidebar:"someSidebar",previous:{title:"Inference",permalink:"/docs/overview/inference"},next:{title:"Installation",permalink:"/docs/overview/installation/"}},d=[{value:"Results of Inference",id:"results-of-inference",children:[{value:"Extracting Samples for a Specific Variable",id:"extracting-samples-for-a-specific-variable",children:[],level:3},{value:"Extracting Samples for a Specific Chain",id:"extracting-samples-for-a-specific-chain",children:[],level:3},{value:"Visualizing Distributions",id:"visualizing-distributions",children:[],level:3}],level:2},{value:'<a name="diagnostics"></a>Diagnostics',id:"diagnostics",children:[{value:"Summary Statistics",id:"summary-statistics",children:[],level:3},{value:"Diagnostic Plots",id:"diagnostic-plots",children:[],level:3}],level:2}],c={toc:d};function N(a){var e=a.components,n=(0,s.Z)(a,p);return(0,m.mdx)("wrapper",(0,t.Z)({},c,n,{components:e,mdxType:"MDXLayout"}),(0,m.mdx)("p",null,"Inference results are useful not only for learning posterior distributions, but for verifying that inference ran correctly. We'll cover common techniques for analyzing results in this section. As is the case for everything else in this ",(0,m.mdx)("strong",{parentName:"p"},"Overview"),", the code for this section is available as a notebook on ",(0,m.mdx)("a",{parentName:"p",href:"https://github.com/facebookresearch/beanmachine/blob/main/docs/overview/overview.ipynb"},"GitHub")," and ",(0,m.mdx)("a",{parentName:"p",href:"https://colab.research.google.com/github/facebookresearch/beanmachine/blob/main/docs/overview/overview.ipynb"},"Colab"),"."),(0,m.mdx)("h2",{id:"results-of-inference"},"Results of Inference"),(0,m.mdx)("p",null,"Bean Machine stores the results of inference in an object of type ",(0,m.mdx)("a",{parentName:"p",href:"https://beanmachine.org/api/beanmachine.ppl.inference.monte_carlo_samples.html#beanmachine.ppl.inference.monte_carlo_samples.MonteCarloSamples"},(0,m.mdx)("inlineCode",{parentName:"a"},"MonteCarloSamples")),". Internally, this class uses a dictionary to map random variables to PyTorch tensors of posterior samples. The class can be accessed like a dictionary, and there are additional wrapper methods to make function calls more explicit."),(0,m.mdx)("p",null,"In the ",(0,m.mdx)("a",{parentName:"p",href:"/docs/overview/inference"},"Inference")," section, we obtained results on the disease modeling example by running inference:"),(0,m.mdx)("pre",null,(0,m.mdx)("code",{parentName:"pre",className:"language-py"},"samples = bm.CompositionalInference().infer(\n    queries=[reproduction_rate()],\n    observations=observations,\n    num_samples=7000,\n    num_adaptive_samples=3000,\n    num_chains=4,\n)\nsamples\n")),(0,m.mdx)("pre",null,(0,m.mdx)("code",{parentName:"pre"},"<beanmachine.ppl.inference.monte_carlo_samples.MonteCarloSamples>\n")),(0,m.mdx)("h3",{id:"extracting-samples-for-a-specific-variable"},"Extracting Samples for a Specific Variable"),(0,m.mdx)("p",null,"In order to perform inference on the random variable ",(0,m.mdx)("inlineCode",{parentName:"p"},"reproduction_rate()"),", we added it to the ",(0,m.mdx)("inlineCode",{parentName:"p"},"queries")," list. We can see that it, and no other random variable, is available in ",(0,m.mdx)("inlineCode",{parentName:"p"},"samples"),":"),(0,m.mdx)("pre",null,(0,m.mdx)("code",{parentName:"pre",className:"language-py"},"list(samples.keys())\n")),(0,m.mdx)("pre",null,(0,m.mdx)("code",{parentName:"pre"},"[RVIdentifier(function=<function reproduction_rate>, arguments=())]\n")),(0,m.mdx)("p",null,"To extract the inference results for ",(0,m.mdx)("inlineCode",{parentName:"p"},"reproduction_rate()"),", we can use ",(0,m.mdx)("inlineCode",{parentName:"p"},"get_variable()"),":"),(0,m.mdx)("pre",null,(0,m.mdx)("code",{parentName:"pre",className:"language-py"},"samples.get_variable(reproduction_rate())\n")),(0,m.mdx)("pre",null,(0,m.mdx)("code",{parentName:"pre"},"tensor([[1.0000, 0.4386, 0.2751,  ..., 0.2177, 0.2177, 0.2193],\n        [0.2183, 0.2183, 0.2184,  ..., 0.2177, 0.2177, 0.2177],\n        [0.2170, 0.2180, 0.2183,  ..., 0.2180, 0.2180, 0.2180],\n        [0.2180, 0.2180, 0.2172,  ..., 0.2180, 0.2180, 0.2176]])\n")),(0,m.mdx)("p",null,"The result has shape ",(0,m.mdx)("span",{parentName:"p",className:"math math-inline"},(0,m.mdx)("span",{parentName:"span",className:"katex"},(0,m.mdx)("span",{parentName:"span",className:"katex-mathml"},(0,m.mdx)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,m.mdx)("semantics",{parentName:"math"},(0,m.mdx)("mrow",{parentName:"semantics"},(0,m.mdx)("mn",{parentName:"mrow"},"4"),(0,m.mdx)("mo",{parentName:"mrow"},"\xd7"),(0,m.mdx)("mn",{parentName:"mrow"},"7000")),(0,m.mdx)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"4 \\times 7000")))),(0,m.mdx)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,m.mdx)("span",{parentName:"span",className:"base"},(0,m.mdx)("span",{parentName:"span",className:"strut",style:{height:"0.72777em",verticalAlign:"-0.08333em"}}),(0,m.mdx)("span",{parentName:"span",className:"mord"},"4"),(0,m.mdx)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222222222222222em"}}),(0,m.mdx)("span",{parentName:"span",className:"mbin"},"\xd7"),(0,m.mdx)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222222222222222em"}})),(0,m.mdx)("span",{parentName:"span",className:"base"},(0,m.mdx)("span",{parentName:"span",className:"strut",style:{height:"0.64444em",verticalAlign:"0em"}}),(0,m.mdx)("span",{parentName:"span",className:"mord"},"7"),(0,m.mdx)("span",{parentName:"span",className:"mord"},"0"),(0,m.mdx)("span",{parentName:"span",className:"mord"},"0"),(0,m.mdx)("span",{parentName:"span",className:"mord"},"0"))))),", representing the ",(0,m.mdx)("span",{parentName:"p",className:"math math-inline"},(0,m.mdx)("span",{parentName:"span",className:"katex"},(0,m.mdx)("span",{parentName:"span",className:"katex-mathml"},(0,m.mdx)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,m.mdx)("semantics",{parentName:"math"},(0,m.mdx)("mrow",{parentName:"semantics"},(0,m.mdx)("mn",{parentName:"mrow"},"7000")),(0,m.mdx)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"7000")))),(0,m.mdx)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,m.mdx)("span",{parentName:"span",className:"base"},(0,m.mdx)("span",{parentName:"span",className:"strut",style:{height:"0.64444em",verticalAlign:"0em"}}),(0,m.mdx)("span",{parentName:"span",className:"mord"},"7"),(0,m.mdx)("span",{parentName:"span",className:"mord"},"0"),(0,m.mdx)("span",{parentName:"span",className:"mord"},"0"),(0,m.mdx)("span",{parentName:"span",className:"mord"},"0")))))," samples that we drew in each of the four chains of inference from the posterior distribution."),(0,m.mdx)("p",null,(0,m.mdx)("inlineCode",{parentName:"p"},"MonteCarloSamples")," supports convenient dictionary indexing syntax to obtain the same information:"),(0,m.mdx)("pre",null,(0,m.mdx)("code",{parentName:"pre",className:"language-py"},"samples[reproduction_rate()]\n")),(0,m.mdx)("pre",null,(0,m.mdx)("code",{parentName:"pre"},"tensor([[1.0000, 0.4386, 0.2751,  ..., 0.2177, 0.2177, 0.2193],\n        [0.2183, 0.2183, 0.2184,  ..., 0.2177, 0.2177, 0.2177],\n        [0.2170, 0.2180, 0.2183,  ..., 0.2180, 0.2180, 0.2180],\n        [0.2180, 0.2180, 0.2172,  ..., 0.2180, 0.2180, 0.2176]])\n")),(0,m.mdx)("p",null,"Please note that many inference methods require a small number of samples before they start drawing samples that correctly resemble the posterior distribution. The 3000 samples that we specified in ",(0,m.mdx)("inlineCode",{parentName:"p"},"num_adaptive_samples")," were already excluded for us, so nothing needs to be done here. However, if you use no adaptive samples, we recommend you discard at least a few hundred samples before using your inference results."),(0,m.mdx)("h3",{id:"extracting-samples-for-a-specific-chain"},"Extracting Samples for a Specific Chain"),(0,m.mdx)("p",null,"We'll see how to make use of chains in ",(0,m.mdx)("a",{parentName:"p",href:"#diagnostics"},"Diagnostics"),"; for inspecting the samples themselves, it is often useful to examine each chain individually. The recommended way to access the results of a specific chain is with ",(0,m.mdx)("inlineCode",{parentName:"p"},"get_chain()"),":"),(0,m.mdx)("pre",null,(0,m.mdx)("code",{parentName:"pre",className:"language-py"},"chain = samples.get_chain(chain=0)\nchain\n")),(0,m.mdx)("pre",null,(0,m.mdx)("code",{parentName:"pre"},"<beanmachine.ppl.inference.monte_carlo_samples.MonteCarloSamples>\n")),(0,m.mdx)("p",null,"This returns a new ",(0,m.mdx)("inlineCode",{parentName:"p"},"MonteCarloSamples")," object which is limited to the specified chain. Tensors no longer have a dimension representing the chain:"),(0,m.mdx)("pre",null,(0,m.mdx)("code",{parentName:"pre",className:"language-py"},"chain[reproduction_rate()]\n")),(0,m.mdx)("pre",null,(0,m.mdx)("code",{parentName:"pre"},"tensor([1.0000, 0.4386, 0.2751,  ..., 0.2177, 0.2177, 0.2193])\n")),(0,m.mdx)("h3",{id:"visualizing-distributions"},"Visualizing Distributions"),(0,m.mdx)("p",null,"Visualizing the results of inference can be a great help in understanding them. Since you now know how to access posterior samples, you're free to use whatever visualization tools you prefer."),(0,m.mdx)("pre",null,(0,m.mdx)("code",{parentName:"pre",className:"language-py"},"reproduction_rate_samples = samples.get_chain(0)[reproduction_rate()]\n")),(0,m.mdx)("img",{src:(0,r.default)("/img/posterior_rate_dynamic.png")}),(0,m.mdx)("h2",{id:"diagnostics"},(0,m.mdx)("a",{name:"diagnostics"}),"Diagnostics"),(0,m.mdx)("p",null,"After running inference it is useful to run diagnostic tools to assess reliability of the inference run. Bean Machine provides two standard types of such diagnostic tools, discussed below."),(0,m.mdx)("h3",{id:"summary-statistics"},"Summary Statistics"),(0,m.mdx)("p",null,"Bean Machine provides important summary statistics for individual, numerically-valued random variables. Let's take a look at the code to generate them, and then we'll break down the statistics themselves."),(0,m.mdx)("p",null,"Bean Machine's interface to the ",(0,m.mdx)("a",{parentName:"p",href:"https://arviz-devs.github.io/arviz/"},(0,m.mdx)("inlineCode",{parentName:"a"},"ArviZ"))," libray makes it easy to generate a Pandas ",(0,m.mdx)("inlineCode",{parentName:"p"},"DataFrame")," presenting these statistics for all queried random variables:"),(0,m.mdx)("pre",null,(0,m.mdx)("code",{parentName:"pre",className:"language-py"},'import arviz as az\n\naz.rcParams["stats.hdi_prob"] = 0.89\naz.summary(samples.to_xarray(), round_to=5)\n')),(0,m.mdx)("table",null,(0,m.mdx)("thead",{parentName:"table"},(0,m.mdx)("tr",{parentName:"thead"},(0,m.mdx)("th",{parentName:"tr",align:null}),(0,m.mdx)("th",{parentName:"tr",align:null},(0,m.mdx)("strong",{parentName:"th"},"mean")),(0,m.mdx)("th",{parentName:"tr",align:null},(0,m.mdx)("strong",{parentName:"th"},"sd")),(0,m.mdx)("th",{parentName:"tr",align:null},(0,m.mdx)("strong",{parentName:"th"},"hdi_5.5%")),(0,m.mdx)("th",{parentName:"tr",align:null},(0,m.mdx)("strong",{parentName:"th"},"hdi_94.5%")),(0,m.mdx)("th",{parentName:"tr",align:null},(0,m.mdx)("strong",{parentName:"th"},"mcse_mean")),(0,m.mdx)("th",{parentName:"tr",align:null},(0,m.mdx)("strong",{parentName:"th"},"mcse_sd")),(0,m.mdx)("th",{parentName:"tr",align:null},(0,m.mdx)("strong",{parentName:"th"},"ess_bulk")),(0,m.mdx)("th",{parentName:"tr",align:null},(0,m.mdx)("strong",{parentName:"th"},"ess_tail")),(0,m.mdx)("th",{parentName:"tr",align:null},(0,m.mdx)("strong",{parentName:"th"},"r_hat")))),(0,m.mdx)("tbody",{parentName:"table"},(0,m.mdx)("tr",{parentName:"tbody"},(0,m.mdx)("td",{parentName:"tr",align:null},(0,m.mdx)("inlineCode",{parentName:"td"},"reproduction_rate()")),(0,m.mdx)("td",{parentName:"tr",align:null},"0.2196"),(0,m.mdx)("td",{parentName:"tr",align:null},"0.0003"),(0,m.mdx)("td",{parentName:"tr",align:null},"0.2192"),(0,m.mdx)("td",{parentName:"tr",align:null},"0.2201"),(0,m.mdx)("td",{parentName:"tr",align:null},"0.0"),(0,m.mdx)("td",{parentName:"tr",align:null},"0.0"),(0,m.mdx)("td",{parentName:"tr",align:null},"19252.377"),(0,m.mdx)("td",{parentName:"tr",align:null},"19175.7875"),(0,m.mdx)("td",{parentName:"tr",align:null},"1.0002")))),(0,m.mdx)("p",null,"We recommend reading the official ",(0,m.mdx)("a",{parentName:"p",href:"https://arviz-devs.github.io/arviz/api/generated/arviz.summary.html"},(0,m.mdx)("inlineCode",{parentName:"a"},"ArviZ")," documentation")," for a full explanation, but the statistics presented are:"),(0,m.mdx)("ol",null,(0,m.mdx)("li",{parentName:"ol"},(0,m.mdx)("strong",{parentName:"li"},"Mean")," and ",(0,m.mdx)("strong",{parentName:"li"},"standard deviation")," (SD)."),(0,m.mdx)("li",{parentName:"ol"},"89% ",(0,m.mdx)("strong",{parentName:"li"},"highest density interval")," (HDI)."),(0,m.mdx)("li",{parentName:"ol"},(0,m.mdx)("strong",{parentName:"li"},"Markov chain standard error")," (MCSE)."),(0,m.mdx)("li",{parentName:"ol"},(0,m.mdx)("strong",{parentName:"li"},"Effective sample size")," (ESS) ",(0,m.mdx)("a",{parentName:"li",href:"https://www.mcmchandbook.net/HandbookChapter1.pdf"},(0,m.mdx)("span",{parentName:"a",className:"math math-inline"},(0,m.mdx)("span",{parentName:"span",className:"katex"},(0,m.mdx)("span",{parentName:"span",className:"katex-mathml"},(0,m.mdx)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,m.mdx)("semantics",{parentName:"math"},(0,m.mdx)("mrow",{parentName:"semantics"},(0,m.mdx)("msub",{parentName:"mrow"},(0,m.mdx)("mi",{parentName:"msub"},"N"),(0,m.mdx)("mtext",{parentName:"msub"},"eff"))),(0,m.mdx)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"N_\\text{eff}")))),(0,m.mdx)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,m.mdx)("span",{parentName:"span",className:"base"},(0,m.mdx)("span",{parentName:"span",className:"strut",style:{height:"0.83333em",verticalAlign:"-0.15em"}}),(0,m.mdx)("span",{parentName:"span",className:"mord"},(0,m.mdx)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.10903em"}},"N"),(0,m.mdx)("span",{parentName:"span",className:"msupsub"},(0,m.mdx)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,m.mdx)("span",{parentName:"span",className:"vlist-r"},(0,m.mdx)("span",{parentName:"span",className:"vlist",style:{height:"0.33610799999999996em"}},(0,m.mdx)("span",{parentName:"span",style:{top:"-2.5500000000000003em",marginLeft:"-0.10903em",marginRight:"0.05em"}},(0,m.mdx)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,m.mdx)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,m.mdx)("span",{parentName:"span",className:"mord text mtight"},(0,m.mdx)("span",{parentName:"span",className:"mord mtight"},"eff"))))),(0,m.mdx)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,m.mdx)("span",{parentName:"span",className:"vlist-r"},(0,m.mdx)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,m.mdx)("span",{parentName:"span"}))))))))))),"."),(0,m.mdx)("li",{parentName:"ol"},(0,m.mdx)("strong",{parentName:"li"},"Convergence diagnostic")," ",(0,m.mdx)("a",{parentName:"li",href:"https://dx.doi.org/10.1214/20-BA1221"},(0,m.mdx)("span",{parentName:"a",className:"math math-inline"},(0,m.mdx)("span",{parentName:"span",className:"katex"},(0,m.mdx)("span",{parentName:"span",className:"katex-mathml"},(0,m.mdx)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,m.mdx)("semantics",{parentName:"math"},(0,m.mdx)("mrow",{parentName:"semantics"},(0,m.mdx)("mover",{parentName:"mrow",accent:"true"},(0,m.mdx)("mi",{parentName:"mover"},"R"),(0,m.mdx)("mo",{parentName:"mover"},"^"))),(0,m.mdx)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"\\hat{R}")))),(0,m.mdx)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,m.mdx)("span",{parentName:"span",className:"base"},(0,m.mdx)("span",{parentName:"span",className:"strut",style:{height:"0.9467699999999999em",verticalAlign:"0em"}}),(0,m.mdx)("span",{parentName:"span",className:"mord accent"},(0,m.mdx)("span",{parentName:"span",className:"vlist-t"},(0,m.mdx)("span",{parentName:"span",className:"vlist-r"},(0,m.mdx)("span",{parentName:"span",className:"vlist",style:{height:"0.9467699999999999em"}},(0,m.mdx)("span",{parentName:"span",style:{top:"-3em"}},(0,m.mdx)("span",{parentName:"span",className:"pstrut",style:{height:"3em"}}),(0,m.mdx)("span",{parentName:"span",className:"mord"},(0,m.mdx)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.00773em"}},"R"))),(0,m.mdx)("span",{parentName:"span",style:{top:"-3.25233em"}},(0,m.mdx)("span",{parentName:"span",className:"pstrut",style:{height:"3em"}}),(0,m.mdx)("span",{parentName:"span",className:"accent-body",style:{left:"-0.16666em"}},(0,m.mdx)("span",{parentName:"span",className:"mord"},"^")))))))))))),".")),(0,m.mdx)("p",null,"We choose to display the 89% highest density interval (HDI), following recommendations in ",(0,m.mdx)("a",{parentName:"p",href:"https://dx.doi.org/10.1201/9780429029608"},(0,m.mdx)("em",{parentName:"a"},"Statistical Rethinking: A Bayesian Course with Examples in R and Stan (McElreath, 2020)")),". The statistics above provide different insights into the quality of the results of inference. For instance, we can use them in combination with synthetically generated data for which we know ground truth values for parameters and then check to make sure that these values fall within some HDI of our posterior samples. Of course, in doing so it is important to keep in mind that the prior distributions in our model (and not just the data) will have an influence on the posterior distribution. Similarly, we can use the size of the HDI to gain insights into the model: if it is large, this could indicate that either we have too few observations or that the prior is too weak."),(0,m.mdx)("p",null,(0,m.mdx)("span",{parentName:"p",className:"math math-inline"},(0,m.mdx)("span",{parentName:"span",className:"katex"},(0,m.mdx)("span",{parentName:"span",className:"katex-mathml"},(0,m.mdx)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,m.mdx)("semantics",{parentName:"math"},(0,m.mdx)("mrow",{parentName:"semantics"},(0,m.mdx)("mover",{parentName:"mrow",accent:"true"},(0,m.mdx)("mi",{parentName:"mover"},"R"),(0,m.mdx)("mo",{parentName:"mover"},"^")),(0,m.mdx)("mo",{parentName:"mrow"},"\u2208"),(0,m.mdx)("mo",{parentName:"mrow",stretchy:"false"},"["),(0,m.mdx)("mn",{parentName:"mrow"},"1"),(0,m.mdx)("mo",{parentName:"mrow",separator:"true"},","),(0,m.mdx)("mi",{parentName:"mrow",mathvariant:"normal"},"\u221e"),(0,m.mdx)("mo",{parentName:"mrow",stretchy:"false"},")")),(0,m.mdx)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"\\hat{R} \\in [1, \\infty)")))),(0,m.mdx)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,m.mdx)("span",{parentName:"span",className:"base"},(0,m.mdx)("span",{parentName:"span",className:"strut",style:{height:"0.9858699999999999em",verticalAlign:"-0.0391em"}}),(0,m.mdx)("span",{parentName:"span",className:"mord accent"},(0,m.mdx)("span",{parentName:"span",className:"vlist-t"},(0,m.mdx)("span",{parentName:"span",className:"vlist-r"},(0,m.mdx)("span",{parentName:"span",className:"vlist",style:{height:"0.9467699999999999em"}},(0,m.mdx)("span",{parentName:"span",style:{top:"-3em"}},(0,m.mdx)("span",{parentName:"span",className:"pstrut",style:{height:"3em"}}),(0,m.mdx)("span",{parentName:"span",className:"mord"},(0,m.mdx)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.00773em"}},"R"))),(0,m.mdx)("span",{parentName:"span",style:{top:"-3.25233em"}},(0,m.mdx)("span",{parentName:"span",className:"pstrut",style:{height:"3em"}}),(0,m.mdx)("span",{parentName:"span",className:"accent-body",style:{left:"-0.16666em"}},(0,m.mdx)("span",{parentName:"span",className:"mord"},"^"))))))),(0,m.mdx)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2777777777777778em"}}),(0,m.mdx)("span",{parentName:"span",className:"mrel"},"\u2208"),(0,m.mdx)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2777777777777778em"}})),(0,m.mdx)("span",{parentName:"span",className:"base"},(0,m.mdx)("span",{parentName:"span",className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,m.mdx)("span",{parentName:"span",className:"mopen"},"["),(0,m.mdx)("span",{parentName:"span",className:"mord"},"1"),(0,m.mdx)("span",{parentName:"span",className:"mpunct"},","),(0,m.mdx)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.16666666666666666em"}}),(0,m.mdx)("span",{parentName:"span",className:"mord"},"\u221e"),(0,m.mdx)("span",{parentName:"span",className:"mclose"},")")))))," summarizes how effective inference was at converging on the correct posterior distribution for a particular random variable. It uses information from all chains run in order to assess whether inference had a good understanding of the distribution or not. Values very close to ",(0,m.mdx)("span",{parentName:"p",className:"math math-inline"},(0,m.mdx)("span",{parentName:"span",className:"katex"},(0,m.mdx)("span",{parentName:"span",className:"katex-mathml"},(0,m.mdx)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,m.mdx)("semantics",{parentName:"math"},(0,m.mdx)("mrow",{parentName:"semantics"},(0,m.mdx)("mn",{parentName:"mrow"},"1.0")),(0,m.mdx)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"1.0")))),(0,m.mdx)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,m.mdx)("span",{parentName:"span",className:"base"},(0,m.mdx)("span",{parentName:"span",className:"strut",style:{height:"0.64444em",verticalAlign:"0em"}}),(0,m.mdx)("span",{parentName:"span",className:"mord"},"1"),(0,m.mdx)("span",{parentName:"span",className:"mord"},"."),(0,m.mdx)("span",{parentName:"span",className:"mord"},"0")))))," indicate that all chains discovered similar distributions for a particular random variable. We do not recommend using inference results where ",(0,m.mdx)("span",{parentName:"p",className:"math math-inline"},(0,m.mdx)("span",{parentName:"span",className:"katex"},(0,m.mdx)("span",{parentName:"span",className:"katex-mathml"},(0,m.mdx)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,m.mdx)("semantics",{parentName:"math"},(0,m.mdx)("mrow",{parentName:"semantics"},(0,m.mdx)("mover",{parentName:"mrow",accent:"true"},(0,m.mdx)("mi",{parentName:"mover"},"R"),(0,m.mdx)("mo",{parentName:"mover"},"^")),(0,m.mdx)("mo",{parentName:"mrow"},">"),(0,m.mdx)("mn",{parentName:"mrow"},"1.01")),(0,m.mdx)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"\\hat{R} > 1.01")))),(0,m.mdx)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,m.mdx)("span",{parentName:"span",className:"base"},(0,m.mdx)("span",{parentName:"span",className:"strut",style:{height:"0.9858699999999999em",verticalAlign:"-0.0391em"}}),(0,m.mdx)("span",{parentName:"span",className:"mord accent"},(0,m.mdx)("span",{parentName:"span",className:"vlist-t"},(0,m.mdx)("span",{parentName:"span",className:"vlist-r"},(0,m.mdx)("span",{parentName:"span",className:"vlist",style:{height:"0.9467699999999999em"}},(0,m.mdx)("span",{parentName:"span",style:{top:"-3em"}},(0,m.mdx)("span",{parentName:"span",className:"pstrut",style:{height:"3em"}}),(0,m.mdx)("span",{parentName:"span",className:"mord"},(0,m.mdx)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.00773em"}},"R"))),(0,m.mdx)("span",{parentName:"span",style:{top:"-3.25233em"}},(0,m.mdx)("span",{parentName:"span",className:"pstrut",style:{height:"3em"}}),(0,m.mdx)("span",{parentName:"span",className:"accent-body",style:{left:"-0.16666em"}},(0,m.mdx)("span",{parentName:"span",className:"mord"},"^"))))))),(0,m.mdx)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2777777777777778em"}}),(0,m.mdx)("span",{parentName:"span",className:"mrel"},">"),(0,m.mdx)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2777777777777778em"}})),(0,m.mdx)("span",{parentName:"span",className:"base"},(0,m.mdx)("span",{parentName:"span",className:"strut",style:{height:"0.64444em",verticalAlign:"0em"}}),(0,m.mdx)("span",{parentName:"span",className:"mord"},"1"),(0,m.mdx)("span",{parentName:"span",className:"mord"},"."),(0,m.mdx)("span",{parentName:"span",className:"mord"},"0"),(0,m.mdx)("span",{parentName:"span",className:"mord"},"1"))))),", as inference may not have converged. In that case, you may want to run inference for more samples. However, there are situations in which increasing the number of samples will not improve convergence. In this case, it is possible that the prior is too far from the posterior, or that the particular inference method is unable to reliably explore the posterior distribution."),(0,m.mdx)("p",null,(0,m.mdx)("span",{parentName:"p",className:"math math-inline"},(0,m.mdx)("span",{parentName:"span",className:"katex"},(0,m.mdx)("span",{parentName:"span",className:"katex-mathml"},(0,m.mdx)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,m.mdx)("semantics",{parentName:"math"},(0,m.mdx)("mrow",{parentName:"semantics"},(0,m.mdx)("msub",{parentName:"mrow"},(0,m.mdx)("mi",{parentName:"msub"},"N"),(0,m.mdx)("mtext",{parentName:"msub"},"eff")),(0,m.mdx)("mo",{parentName:"mrow"},"\u2208"),(0,m.mdx)("mo",{parentName:"mrow",stretchy:"false"},"["),(0,m.mdx)("mn",{parentName:"mrow"},"1"),(0,m.mdx)("mo",{parentName:"mrow",separator:"true"},",")),(0,m.mdx)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"N_\\text{eff} \\in [1,")))),(0,m.mdx)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,m.mdx)("span",{parentName:"span",className:"base"},(0,m.mdx)("span",{parentName:"span",className:"strut",style:{height:"0.83333em",verticalAlign:"-0.15em"}}),(0,m.mdx)("span",{parentName:"span",className:"mord"},(0,m.mdx)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.10903em"}},"N"),(0,m.mdx)("span",{parentName:"span",className:"msupsub"},(0,m.mdx)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,m.mdx)("span",{parentName:"span",className:"vlist-r"},(0,m.mdx)("span",{parentName:"span",className:"vlist",style:{height:"0.33610799999999996em"}},(0,m.mdx)("span",{parentName:"span",style:{top:"-2.5500000000000003em",marginLeft:"-0.10903em",marginRight:"0.05em"}},(0,m.mdx)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,m.mdx)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,m.mdx)("span",{parentName:"span",className:"mord text mtight"},(0,m.mdx)("span",{parentName:"span",className:"mord mtight"},"eff"))))),(0,m.mdx)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,m.mdx)("span",{parentName:"span",className:"vlist-r"},(0,m.mdx)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,m.mdx)("span",{parentName:"span"})))))),(0,m.mdx)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2777777777777778em"}}),(0,m.mdx)("span",{parentName:"span",className:"mrel"},"\u2208"),(0,m.mdx)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2777777777777778em"}})),(0,m.mdx)("span",{parentName:"span",className:"base"},(0,m.mdx)("span",{parentName:"span",className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,m.mdx)("span",{parentName:"span",className:"mopen"},"["),(0,m.mdx)("span",{parentName:"span",className:"mord"},"1"),(0,m.mdx)("span",{parentName:"span",className:"mpunct"},",")))))," ",(0,m.mdx)("inlineCode",{parentName:"p"},"num_samples"),(0,m.mdx)("span",{parentName:"p",className:"math math-inline"},(0,m.mdx)("span",{parentName:"span",className:"katex"},(0,m.mdx)("span",{parentName:"span",className:"katex-mathml"},(0,m.mdx)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,m.mdx)("semantics",{parentName:"math"},(0,m.mdx)("mrow",{parentName:"semantics"},(0,m.mdx)("mo",{parentName:"mrow",stretchy:"false"},"]")),(0,m.mdx)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"]")))),(0,m.mdx)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,m.mdx)("span",{parentName:"span",className:"base"},(0,m.mdx)("span",{parentName:"span",className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,m.mdx)("span",{parentName:"span",className:"mclose"},"]")))))," summarizes how independent posterior samples are from one another. Although inference was run for ",(0,m.mdx)("inlineCode",{parentName:"p"},"num_samples")," iterations, it's possible that those samples were very similar to each other (due to the way inference is implemented), and may not each be representative of the full posterior space. Larger numbers are better here, and if your particular use case calls for a certain number of samples to be considered, you should ensure that ",(0,m.mdx)("span",{parentName:"p",className:"math math-inline"},(0,m.mdx)("span",{parentName:"span",className:"katex"},(0,m.mdx)("span",{parentName:"span",className:"katex-mathml"},(0,m.mdx)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,m.mdx)("semantics",{parentName:"math"},(0,m.mdx)("mrow",{parentName:"semantics"},(0,m.mdx)("msub",{parentName:"mrow"},(0,m.mdx)("mi",{parentName:"msub"},"N"),(0,m.mdx)("mtext",{parentName:"msub"},"eff"))),(0,m.mdx)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"N_\\text{eff}")))),(0,m.mdx)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,m.mdx)("span",{parentName:"span",className:"base"},(0,m.mdx)("span",{parentName:"span",className:"strut",style:{height:"0.83333em",verticalAlign:"-0.15em"}}),(0,m.mdx)("span",{parentName:"span",className:"mord"},(0,m.mdx)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.10903em"}},"N"),(0,m.mdx)("span",{parentName:"span",className:"msupsub"},(0,m.mdx)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,m.mdx)("span",{parentName:"span",className:"vlist-r"},(0,m.mdx)("span",{parentName:"span",className:"vlist",style:{height:"0.33610799999999996em"}},(0,m.mdx)("span",{parentName:"span",style:{top:"-2.5500000000000003em",marginLeft:"-0.10903em",marginRight:"0.05em"}},(0,m.mdx)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,m.mdx)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,m.mdx)("span",{parentName:"span",className:"mord text mtight"},(0,m.mdx)("span",{parentName:"span",className:"mord mtight"},"eff"))))),(0,m.mdx)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,m.mdx)("span",{parentName:"span",className:"vlist-r"},(0,m.mdx)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,m.mdx)("span",{parentName:"span"}))))))))))," is at least that large.  For more information on R-hat and ",(0,m.mdx)("span",{parentName:"p",className:"math math-inline"},(0,m.mdx)("span",{parentName:"span",className:"katex"},(0,m.mdx)("span",{parentName:"span",className:"katex-mathml"},(0,m.mdx)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,m.mdx)("semantics",{parentName:"math"},(0,m.mdx)("mrow",{parentName:"semantics"},(0,m.mdx)("msub",{parentName:"mrow"},(0,m.mdx)("mi",{parentName:"msub"},"N"),(0,m.mdx)("mtext",{parentName:"msub"},"eff"))),(0,m.mdx)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"N_\\text{eff}")))),(0,m.mdx)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,m.mdx)("span",{parentName:"span",className:"base"},(0,m.mdx)("span",{parentName:"span",className:"strut",style:{height:"0.83333em",verticalAlign:"-0.15em"}}),(0,m.mdx)("span",{parentName:"span",className:"mord"},(0,m.mdx)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.10903em"}},"N"),(0,m.mdx)("span",{parentName:"span",className:"msupsub"},(0,m.mdx)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,m.mdx)("span",{parentName:"span",className:"vlist-r"},(0,m.mdx)("span",{parentName:"span",className:"vlist",style:{height:"0.33610799999999996em"}},(0,m.mdx)("span",{parentName:"span",style:{top:"-2.5500000000000003em",marginLeft:"-0.10903em",marginRight:"0.05em"}},(0,m.mdx)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,m.mdx)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,m.mdx)("span",{parentName:"span",className:"mord text mtight"},(0,m.mdx)("span",{parentName:"span",className:"mord mtight"},"eff"))))),(0,m.mdx)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,m.mdx)("span",{parentName:"span",className:"vlist-r"},(0,m.mdx)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,m.mdx)("span",{parentName:"span"})))))))))),", see the ",(0,m.mdx)("a",{parentName:"p",href:"../../diagnostics/"},"Diagnostics Section"),"."),(0,m.mdx)("p",null,"In the case of our example model, we have a healthy ",(0,m.mdx)("span",{parentName:"p",className:"math math-inline"},(0,m.mdx)("span",{parentName:"span",className:"katex"},(0,m.mdx)("span",{parentName:"span",className:"katex-mathml"},(0,m.mdx)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,m.mdx)("semantics",{parentName:"math"},(0,m.mdx)("mrow",{parentName:"semantics"},(0,m.mdx)("mover",{parentName:"mrow",accent:"true"},(0,m.mdx)("mi",{parentName:"mover"},"R"),(0,m.mdx)("mo",{parentName:"mover"},"^"))),(0,m.mdx)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"\\hat{R}")))),(0,m.mdx)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,m.mdx)("span",{parentName:"span",className:"base"},(0,m.mdx)("span",{parentName:"span",className:"strut",style:{height:"0.9467699999999999em",verticalAlign:"0em"}}),(0,m.mdx)("span",{parentName:"span",className:"mord accent"},(0,m.mdx)("span",{parentName:"span",className:"vlist-t"},(0,m.mdx)("span",{parentName:"span",className:"vlist-r"},(0,m.mdx)("span",{parentName:"span",className:"vlist",style:{height:"0.9467699999999999em"}},(0,m.mdx)("span",{parentName:"span",style:{top:"-3em"}},(0,m.mdx)("span",{parentName:"span",className:"pstrut",style:{height:"3em"}}),(0,m.mdx)("span",{parentName:"span",className:"mord"},(0,m.mdx)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.00773em"}},"R"))),(0,m.mdx)("span",{parentName:"span",style:{top:"-3.25233em"}},(0,m.mdx)("span",{parentName:"span",className:"pstrut",style:{height:"3em"}}),(0,m.mdx)("span",{parentName:"span",className:"accent-body",style:{left:"-0.16666em"}},(0,m.mdx)("span",{parentName:"span",className:"mord"},"^")))))))))))," value very close to 1.0, and a healthy relative number of effective samples."),(0,m.mdx)("h3",{id:"diagnostic-plots"},"Diagnostic Plots"),(0,m.mdx)("p",null,"Bean Machine can also plot diagnostic information to assess health of the inference run. Let's take a look:"),(0,m.mdx)("pre",null,(0,m.mdx)("code",{parentName:"pre",className:"language-py"},'az.plot_trace(\n    {"Reproduction rate": samples[reproduction_rate()]},\n    compact=False,\n)\n')),(0,m.mdx)("img",{src:(0,r.default)("/img/mcmc_trace.png")}),(0,m.mdx)("pre",null,(0,m.mdx)("code",{parentName:"pre",className:"language-py"},'az.plot_autocorr({"Reproduction rate": samples[reproduction_rate()]})\n')),(0,m.mdx)("img",{src:(0,r.default)("/img/mcmc_autocorr.png")}),(0,m.mdx)("p",null,"The diagnostics output shows two diagnostic plots for individual random variables: trace plots and autocorrelation plots."),(0,m.mdx)("ul",null,(0,m.mdx)("li",{parentName:"ul"},"Trace plots are simply a time series of values assigned to random variables over each iteration of inference. The concrete values assigned are usually problem-specific. However, it's important that these values are \"mixing\" well over time. This means that they don't tend to get stuck in one region for large periods of time, and that each of the chains ends up exploring the same space as the other chains throughout the course of inference."),(0,m.mdx)("li",{parentName:"ul"},"Autocorrelation plots measure how predictive the last several samples are of the current sample. Autocorrelation may vary between -1.0 (deterministically anticorrelated) and 1.0 (deterministically correlated). (We compute autocorrelation approximately, so it may sometimes exceed these bounds.) In an ideal world, the current sample is chosen independently of the previous samples: an autocorrelation of zero. This is not possible in practice, due to stochastic noise and the mechanics of how inference works. The autocorrelation plots here plot how correlated samples from the end of the chain are compared with samples taken from elsewhere within the chain, as indicated by the iteration index on the x axis.")),(0,m.mdx)("p",null,"For our example model, we see from the trace plots that each of the chains are healthy: they don't get stuck, and do not explore a chain-specific subset of the space. From the autocorrelation plots, we see the absolute magnitude of autocorrelation to be very small, often well below ",(0,m.mdx)("span",{parentName:"p",className:"math math-inline"},(0,m.mdx)("span",{parentName:"span",className:"katex"},(0,m.mdx)("span",{parentName:"span",className:"katex-mathml"},(0,m.mdx)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,m.mdx)("semantics",{parentName:"math"},(0,m.mdx)("mrow",{parentName:"semantics"},(0,m.mdx)("mn",{parentName:"mrow"},"0.1")),(0,m.mdx)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"0.1")))),(0,m.mdx)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,m.mdx)("span",{parentName:"span",className:"base"},(0,m.mdx)("span",{parentName:"span",className:"strut",style:{height:"0.64444em",verticalAlign:"0em"}}),(0,m.mdx)("span",{parentName:"span",className:"mord"},"0"),(0,m.mdx)("span",{parentName:"span",className:"mord"},"."),(0,m.mdx)("span",{parentName:"span",className:"mord"},"1"))))),", indicating a healthy exploration of the space."),(0,m.mdx)("hr",null),(0,m.mdx)("p",null,"Congratulations, you've made it through the ",(0,m.mdx)("strong",{parentName:"p"},"Overview"),"! If you're looking to get an even deeper understanding of Bean Machine, check out the ",(0,m.mdx)("strong",{parentName:"p"},"Framework")," topics next. Or, if you're looking to get to coding, check out our ",(0,m.mdx)("a",{parentName:"p",href:"/docs/tutorials"},(0,m.mdx)("strong",{parentName:"a"},"Tutorials")),". In either case, happy modeling!"))}N.isMDXComponent=!0}}]);